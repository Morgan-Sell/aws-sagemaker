{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "  Downloading pip-20.1.1-py2.py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 4.2 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 20.0.2\n",
      "    Uninstalling pip-20.0.2:\n",
      "      Successfully uninstalled pip-20.0.2\n",
      "Successfully installed pip-20.1.1\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.2.0-cp36-cp36m-manylinux2010_x86_64.whl (516.2 MB)\n",
      "\u001b[K     |███████████████████▎            | 310.1 MB 21.5 MB/s eta 0:00:103     |████████████▌                   | 200.8 MB 103.6 MB/s eta 0:00:04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 516.2 MB 12 kB/s /s eta 0:00:01\n",
      "\u001b[?25hCollecting google-pasta>=0.1.8\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 1.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.2.1-py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 5.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.4.1)\n",
      "Collecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting tensorboard<2.3.0,>=2.2.0\n",
      "  Downloading tensorboard-2.2.2-py3-none-any.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 70.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astunparse==1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (2.10.0)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting grpcio>=1.8.6\n",
      "  Downloading grpcio-1.29.0-cp36-cp36m-manylinux2010_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 84.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.12.0)\n",
      "Collecting tensorflow-estimator<2.3.0,>=2.2.0\n",
      "  Downloading tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454 kB)\n",
      "\u001b[K     |████████████████████████████████| 454 kB 71.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py>=0.7.0\n",
      "  Downloading absl-py-0.9.0.tar.gz (104 kB)\n",
      "\u001b[K     |████████████████████████████████| 104 kB 102.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.12.1)\n",
      "Collecting keras-preprocessing>=1.1.0\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 421 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.18.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.0.1)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.16.1-py2.py3-none-any.whl (90 kB)\n",
      "\u001b[K     |████████████████████████████████| 90 kB 21.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.2.2-py3-none-any.whl (88 kB)\n",
      "\u001b[K     |████████████████████████████████| 88 kB 19.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.23.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (46.1.3.post20200330)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.6.0.post3-py3-none-any.whl (777 kB)\n",
      "\u001b[K     |████████████████████████████████| 777 kB 105.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.1.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.4.2)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 100.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.5.0)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2020.4.5.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.25.8)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.2.0)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 102.4 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: termcolor, absl-py\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=e3fc2090afc9d965038e3ef5117fc16f00343333eb2d5498a45593947d4870c9\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n",
      "  Building wheel for absl-py (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for absl-py: filename=absl_py-0.9.0-py3-none-any.whl size=121931 sha256=099722015244df3b669f0f042f0b77eeace9634d95a6c347e36c124a9ddc3fd8\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/c3/af/84/3962a6af7b4ab336e951b7877dcfb758cf94548bb1771e0679\n",
      "Successfully built termcolor absl-py\n",
      "Installing collected packages: google-pasta, opt-einsum, gast, grpcio, cachetools, pyasn1-modules, google-auth, absl-py, markdown, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard-plugin-wit, tensorboard, astunparse, termcolor, tensorflow-estimator, keras-preprocessing, tensorflow\n",
      "Successfully installed absl-py-0.9.0 astunparse-1.6.3 cachetools-4.1.0 gast-0.3.3 google-auth-1.16.1 google-auth-oauthlib-0.4.1 google-pasta-0.2.0 grpcio-1.29.0 keras-preprocessing-1.1.2 markdown-3.2.2 oauthlib-3.1.0 opt-einsum-3.2.1 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 tensorboard-2.2.2 tensorboard-plugin-wit-1.6.0.post3 tensorflow-2.2.0 tensorflow-estimator-2.2.0 termcolor-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyflux\n",
      "  Downloading pyflux-0.4.15.tar.gz (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 4.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyflux) (1.18.1)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyflux) (1.0.3)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyflux) (1.4.1)\n",
      "Collecting numdifftools\n",
      "  Downloading numdifftools-0.9.39-py2.py3-none-any.whl (953 kB)\n",
      "\u001b[K     |████████████████████████████████| 953 kB 13.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: patsy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyflux) (0.5.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas->pyflux) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas->pyflux) (2.8.1)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from patsy->pyflux) (1.14.0)\n",
      "Building wheels for collected packages: pyflux\n",
      "  Building wheel for pyflux (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyflux: filename=pyflux-0.4.15-cp36-cp36m-linux_x86_64.whl size=5130318 sha256=4655ae817e2b24b62fd14d8052062178ae784383d8229b6cfc1263e73f9714c5\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/d0/75/75/5e6c26d910209766f8aa4bd6940e391277eb3ec2a3501f9965\n",
      "Successfully built pyflux\n",
      "Installing collected packages: numdifftools, pyflux\n",
      "Successfully installed numdifftools-0.9.39 pyflux-0.4.15\n"
     ]
    }
   ],
   "source": [
    "!pip install pyflux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.arima_process import ArmaProcess\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.graphics.gofplots import qqplot_2samples\n",
    "from statsmodels.tsa.vector_ar.var_model import VAR\n",
    "\n",
    "import pyflux as pf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy import stats\n",
    "\n",
    "import tensorflow as tf\n",
    "keras = tf.keras\n",
    "\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# User-defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_rmse(actual, pred):\n",
    "    return np.sqrt(mean_squared_error(actual, pred))\n",
    "\n",
    "def windowize_data(data, n_prev):\n",
    "    n_predictions = len(data) - n_prev\n",
    "    y = data[n_prev:]\n",
    "    # this might be too clever\n",
    "    indices = np.arange(n_prev) + np.arange(n_predictions)[:, None]\n",
    "    x = data[indices, None]\n",
    "    return x, y\n",
    "\n",
    "def split_and_windowize(data, n_prev, fraction_test=0.3):\n",
    "    n_predictions = len(data) - 2*n_prev\n",
    "    \n",
    "    n_test  = int(fraction_test * n_predictions)\n",
    "    n_train = n_predictions - n_test   \n",
    "    \n",
    "    x_train, y_train = windowize_data(data[:n_train], n_prev)\n",
    "    x_test, y_test = windowize_data(data[n_train:], n_prev)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "def lstm_uni_train_test_split(lmp_curve, n_prev, date_delim_idx):\n",
    "    lmp_train = lmp_curve[:date_delim_idx]\n",
    "    lmp_test = lmp_curve[date_delim_idx:]\n",
    "    X_train, y_train = windowize_data(lmp_train, n_prev)\n",
    "    X_test, y_test = windowize_data(lmp_test, n_prev)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Data Import and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_process_data():\n",
    "    caiso = pd.read_csv('data/caiso_master.csv')\n",
    "    caiso.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "    caiso['INTERVAL_START_PT'] = pd.to_datetime(caiso['INTERVAL_START_PT']).apply(lambda x: x.replace(tzinfo=None))\n",
    "    caiso['INTERVAL_END_PT'] = pd.to_datetime(caiso['INTERVAL_END_PT']).apply(lambda x: x.replace(tzinfo=None))\n",
    "    caiso['date_hour_start'] = pd.to_datetime(caiso['date_hour_start']).apply(lambda x: x.replace(tzinfo=None))\n",
    "    caiso['OPR_DT_PT'] = pd.to_datetime(caiso['OPR_DT_PT']).apply(lambda x: x.replace(tzinfo=None))\n",
    "#     caiso.set_index('INTERVAL_START_PT', inplace=True)\n",
    "    caiso.rename({'HH_$_million_BTU_not_seasonal_adj': 'HH_$_mill_BTU', 'total_mw':'total_gen'},axis=1, inplace=True)\n",
    "    caiso['HH_$_mill_BTU'] = pd.to_numeric(caiso['HH_$_mill_BTU'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_process_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INTERVAL_END_PT</th>\n",
       "      <th>date_hour_start</th>\n",
       "      <th>OPR_DT_PT</th>\n",
       "      <th>OPR_HR_PT</th>\n",
       "      <th>day_week</th>\n",
       "      <th>OPR_INTERVAL</th>\n",
       "      <th>$_MWH_np15</th>\n",
       "      <th>$_MWH_sp15</th>\n",
       "      <th>$_MWH_zp26</th>\n",
       "      <th>other</th>\n",
       "      <th>solar</th>\n",
       "      <th>wind</th>\n",
       "      <th>total_gen</th>\n",
       "      <th>net_exp_MW</th>\n",
       "      <th>load_MW</th>\n",
       "      <th>HH_$_mill_BTU</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTERVAL_START_PT</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-02-01 01:00:00</th>\n",
       "      <td>2019-02-01 02:00:00</td>\n",
       "      <td>2019-02-01 01:00:00</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>36.62123</td>\n",
       "      <td>36.04269</td>\n",
       "      <td>36.05743</td>\n",
       "      <td>19179.16</td>\n",
       "      <td>71.63</td>\n",
       "      <td>531.70</td>\n",
       "      <td>19782.49</td>\n",
       "      <td>-113560.63</td>\n",
       "      <td>318054.0</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-01 02:00:00</th>\n",
       "      <td>2019-02-01 03:00:00</td>\n",
       "      <td>2019-02-01 02:00:00</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>35.84812</td>\n",
       "      <td>35.15389</td>\n",
       "      <td>35.19706</td>\n",
       "      <td>19252.28</td>\n",
       "      <td>0.27</td>\n",
       "      <td>513.50</td>\n",
       "      <td>19766.05</td>\n",
       "      <td>-111822.96</td>\n",
       "      <td>328601.0</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-01 03:00:00</th>\n",
       "      <td>2019-02-01 04:00:00</td>\n",
       "      <td>2019-02-01 03:00:00</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>35.60431</td>\n",
       "      <td>34.87623</td>\n",
       "      <td>34.92977</td>\n",
       "      <td>18500.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>456.11</td>\n",
       "      <td>18957.09</td>\n",
       "      <td>-111927.13</td>\n",
       "      <td>322692.0</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-01 04:00:00</th>\n",
       "      <td>2019-02-01 05:00:00</td>\n",
       "      <td>2019-02-01 04:00:00</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>35.40240</td>\n",
       "      <td>34.69286</td>\n",
       "      <td>34.73189</td>\n",
       "      <td>17693.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>379.62</td>\n",
       "      <td>18072.78</td>\n",
       "      <td>-112259.17</td>\n",
       "      <td>313214.0</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-01 05:00:00</th>\n",
       "      <td>2019-02-01 06:00:00</td>\n",
       "      <td>2019-02-01 05:00:00</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>36.62816</td>\n",
       "      <td>36.03518</td>\n",
       "      <td>36.04623</td>\n",
       "      <td>16903.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>365.96</td>\n",
       "      <td>17268.98</td>\n",
       "      <td>-105529.79</td>\n",
       "      <td>297274.0</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        INTERVAL_END_PT     date_hour_start  OPR_DT_PT  \\\n",
       "INTERVAL_START_PT                                                        \n",
       "2019-02-01 01:00:00 2019-02-01 02:00:00 2019-02-01 01:00:00 2019-02-01   \n",
       "2019-02-01 02:00:00 2019-02-01 03:00:00 2019-02-01 02:00:00 2019-02-01   \n",
       "2019-02-01 03:00:00 2019-02-01 04:00:00 2019-02-01 03:00:00 2019-02-01   \n",
       "2019-02-01 04:00:00 2019-02-01 05:00:00 2019-02-01 04:00:00 2019-02-01   \n",
       "2019-02-01 05:00:00 2019-02-01 06:00:00 2019-02-01 05:00:00 2019-02-01   \n",
       "\n",
       "                     OPR_HR_PT  day_week  OPR_INTERVAL  $_MWH_np15  \\\n",
       "INTERVAL_START_PT                                                    \n",
       "2019-02-01 01:00:00          1         4             0    36.62123   \n",
       "2019-02-01 02:00:00          2         4             0    35.84812   \n",
       "2019-02-01 03:00:00          3         4             0    35.60431   \n",
       "2019-02-01 04:00:00          4         4             0    35.40240   \n",
       "2019-02-01 05:00:00          5         4             0    36.62816   \n",
       "\n",
       "                     $_MWH_sp15  $_MWH_zp26     other  solar    wind  \\\n",
       "INTERVAL_START_PT                                                      \n",
       "2019-02-01 01:00:00    36.04269    36.05743  19179.16  71.63  531.70   \n",
       "2019-02-01 02:00:00    35.15389    35.19706  19252.28   0.27  513.50   \n",
       "2019-02-01 03:00:00    34.87623    34.92977  18500.98   0.00  456.11   \n",
       "2019-02-01 04:00:00    34.69286    34.73189  17693.16   0.00  379.62   \n",
       "2019-02-01 05:00:00    36.03518    36.04623  16903.02   0.00  365.96   \n",
       "\n",
       "                     total_gen  net_exp_MW   load_MW  HH_$_mill_BTU  \n",
       "INTERVAL_START_PT                                                    \n",
       "2019-02-01 01:00:00   19782.49  -113560.63  318054.0            2.7  \n",
       "2019-02-01 02:00:00   19766.05  -111822.96  328601.0            2.7  \n",
       "2019-02-01 03:00:00   18957.09  -111927.13  322692.0            2.7  \n",
       "2019-02-01 04:00:00   18072.78  -112259.17  313214.0            2.7  \n",
       "2019-02-01 05:00:00   17268.98  -105529.79  297274.0            2.7  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caiso.reset_index(inplace=Tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_lmp_arr = caiso['$_MWH_np15'].values\n",
    "sp_lmp_arr = caiso['$_MWH_sp15'].values\n",
    "zp_lmp_arr = caiso['$_MWH_zp26'].values\n",
    "datetime_arr = caiso.index.to_period('H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11351"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_week_idx = len(caiso) - len(caiso[caiso['OPR_DT_PT'] >= '2020-05-24'])\n",
    "two_week_idx = len(caiso) - len(caiso[caiso['OPR_DT_PT'] >= '2020-05-17'])\n",
    "one_month_idx = len(caiso) - len(caiso[caiso['OPR_DT_PT'] >= '2020-05-01'])\n",
    "two_month_idx = len(caiso) - len(caiso[caiso['OPR_DT_PT'] >= '2020-04-01'])\n",
    "one_week_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ARIMA Univariate Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uni_var_train_test_split(lmp_curve, date_rng, date_delim_idx):\n",
    "    lmp_train_curve = lmp_curve[:date_delim_idx]\n",
    "    lmp_test_curve = lmp_curve[date_delim_idx:]\n",
    "    date_train_rng = date_rng[:date_delim_idx]\n",
    "    date_test_rng = date_rng[date_delim_idx:]\n",
    "    return lmp_train_curve, lmp_test_curve, date_train_rng, date_test_rng\n",
    "\n",
    "def arima_uni_var_fit(lmp_train, date_rng, p, d, q):\n",
    "    return ARIMA(endog=lmp_train, dates=date_rng, order=(p, d, q)).fit()\n",
    "\n",
    "def arima_uni_var_predict(model, n_period_fcst):\n",
    "    return model.forecast(steps=n_period_fcst)[0]\n",
    "\n",
    "def plot_lstm_v_arima_vs_actuals(y_true, y_lstm, y_arima, date_rng):\n",
    "    fig, ax = plt.subplots(figsize=(20,6))\n",
    "    ax.plot(date_rng, y_lstm, 'g.-', label='LSTM', lw=2)\n",
    "    ax.plot(date_rng, y_arima, 'b.-', label='ARIMA', lw=2)\n",
    "    ax.plot(date_rng, y_true, 'r.', label='Actual')\n",
    "    ax.set_title('Prediction vs Actual', fontsize=18, fontweight='bold')\n",
    "    ax.set_xlabel('$/MWh', fontsize=12)\n",
    "    ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# NP-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_date_delim_idx = 11270\n",
    "\n",
    "np_multi_var_df = caiso[['$_MWH_np15', 'load_MW', 'HH_$_mill_BTU', 'other', 'solar', 'wind']].copy()\n",
    "np_multi_var_train = np_multi_var_df.iloc[: train_test_date_delim_idx, :]\n",
    "np_multi_var_test = np_multi_var_df.iloc[train_test_date_delim_idx :, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ARIMA Univariate Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_uni_train, np_uni_test, np_train_rng, np_test_rng = uni_var_train_test_split(np_lmp_arr, datetime_arr, train_test_date_delim_idx)\n",
    "np_uni_arima = arima_uni_var_fit(np_uni_train, np_train_rng, 24, 1, 0)\n",
    "np_uni_arima_pred = arima_uni_var_predict(np_uni_arima, 24 * 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_uni_arima_pred = arima_uni_var_predict(np_uni_arima, 249)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 4.388116\n"
     ]
    }
   ],
   "source": [
    "rmse_np_uni_arima = round(calc_rmse(np_uni_arima_pred, np_uni_test), 6)\n",
    "print(f\"RMSE: {rmse_np_uni_arima}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM Univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 week\n",
    "batch_size = 24 * 7\n",
    "train_test_allocation = batch_size / len(caiso)\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = split_and_windowize(np_lmp_arr, int(batch_size / 2), train_test_allocation)\n",
    "n_features = X1_train.shape[2]\n",
    "\n",
    "np_lstm_uni = keras.Sequential()\n",
    "np_lstm_uni.add(keras.layers.LSTM(32, input_shape=(batch_size, n_features), return_sequences=True))\n",
    "np_lstm_uni.add(keras.layers.LSTM(32, return_sequences=True))\n",
    "np_lstm_uni.add(keras.layers.LSTM(32, return_sequences=False))\n",
    "# The Dense value is the output sequence.\n",
    "np_lstm_uni.add(keras.layers.Dense(1, activation='linear'))\n",
    "np_lstm_uni.compile(optimizer='adam',loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.windowize_data(data, n_prev)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windowize_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 168, 1) for input Tensor(\"lstm_input:0\", shape=(None, 168, 1), dtype=float32), but it was called on an input with incompatible shape (None, 84, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 168, 1) for input Tensor(\"lstm_input:0\", shape=(None, 168, 1), dtype=float32), but it was called on an input with incompatible shape (None, 84, 1).\n",
      "67/67 [==============================] - 8s 119ms/step - loss: 1290.8796\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 8s 114ms/step - loss: 1025.8043\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 8s 114ms/step - loss: 915.2725\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 8s 115ms/step - loss: 829.1397\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 8s 114ms/step - loss: 758.5579\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 8s 114ms/step - loss: 697.0353\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 8s 114ms/step - loss: 639.9954\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 8s 115ms/step - loss: 590.4341\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 8s 115ms/step - loss: 548.7447\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 8s 114ms/step - loss: 512.1461\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 8s 114ms/step - loss: 480.6756\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 8s 115ms/step - loss: 453.4751\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 8s 117ms/step - loss: 429.6758\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 8s 114ms/step - loss: 407.6376\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 8s 114ms/step - loss: 388.4834\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 8s 114ms/step - loss: 371.5962\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 8s 114ms/step - loss: 355.5117\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 8s 114ms/step - loss: 342.6535\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 8s 115ms/step - loss: 328.7173\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 8s 115ms/step - loss: 316.4659\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f56b29f4400>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_lstm_uni.fit(X1_train, y1_train, batch_size, epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 168, 1) for input Tensor(\"lstm_input:0\", shape=(None, 168, 1), dtype=float32), but it was called on an input with incompatible shape (None, 84, 1).\n",
      "RMSE - NP15 LSTM - Endo 2.670197\n"
     ]
    }
   ],
   "source": [
    "np_lstm_pred = np_lstm_uni.predict(X1_test)\n",
    "np_rmse_lstm_uni = round(calc_rmse(y1_test, np_lstm_pred), 6)\n",
    "print(f\"RMSE - NP15 LSTM - Endo {np_rmse_lstm_uni}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((249,), (249, 1), (249,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_test_rng.shape, np_lstm_pred.shape, np_uni_arima_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.indexes.period.PeriodIndex"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# fig, ax = plt.subplots(figsize=(20,6))\n",
    "\n",
    "# pd.plotting.register_matplotlib_converters()\n",
    "\n",
    "# ax.plot(np_test_rng, np_lstm_pred, 'g-', label='LSTM', lw=2)\n",
    "# ax.plot(np_test_rng, np_uni_arima_pred, 'b.-', label='ARIMA', lw=2)\n",
    "# ax.plot(np_test_rng, y1_test, 'r.', label='Actual')\n",
    "# ax.set_title('Prediction vs Actual', fontsize=18, fontweight='bold')\n",
    "# ax.set_xlabel('$/MWh', fontsize=12)\n",
    "# ax.legend();\n",
    "type(np_test_rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PeriodIndex' object has no attribute 'as_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-b857ea651037>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdate_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_test_rng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'O'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PeriodIndex' object has no attribute 'as_type'"
     ]
    }
   ],
   "source": [
    "date_test = np_test_rng.as_type('O')\n",
    "type(date_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-249"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,6))\n",
    "dt = -len(y1_test)\n",
    "\n",
    "ax.plot(datetime_arr[dt:], np_lstm_pred, 'b.-', label='Predictions', lw=2)\n",
    "ax.plot(datetime_arr[dt:], y1_test, 'r.', label='Actual')\n",
    "ax.set_title('NP15 - One Week Forecast', fontsize=18, fontweight='bold')\n",
    "ax.set_xlabel('$/MWh', fontsize=12)\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.791666666666666"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "331 / 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAR - Multivariable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "SVD did not converge in Linear Least Squares",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-5a5a09933f68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnp_var_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVAR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp_multi_var_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_var_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/statsmodels/tsa/vector_ar/var_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, maxlags, method, ic, trend, verbose)\u001b[0m\n\u001b[1;32m    644\u001b[0m         self.data.cov_names = pd.MultiIndex.from_product((self.data.xnames,\n\u001b[1;32m    645\u001b[0m                                                           self.data.ynames))\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_estimate_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_estimate_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/statsmodels/tsa/vector_ar/var_model.py\u001b[0m in \u001b[0;36m_estimate_var\u001b[0;34m(self, lags, offset, trend)\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0my_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mendog\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlags\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m         \u001b[0;31m# Lütkepohl p75, about 5x faster than stated formula\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstsq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m         \u001b[0mresid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_sample\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mlstsq\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mlstsq\u001b[0;34m(a, b, rcond)\u001b[0m\n\u001b[1;32m   2257\u001b[0m         \u001b[0;31m# lapack can't handle n_rhs = 0 - so allocate the array one larger in that axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2258\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rhs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2259\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2260\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2261\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_lstsq\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_lstsq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SVD did not converge in Linear Least Squares\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: SVD did not converge in Linear Least Squares"
     ]
    }
   ],
   "source": [
    "np_var_model = VAR(endog=np_multi_var_train)\n",
    "model_fit = np_var_model.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
